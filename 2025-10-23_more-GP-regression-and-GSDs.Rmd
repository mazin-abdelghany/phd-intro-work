---
title: "More coding examples"
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
date: "2025-10-17"
---

```{css, echo=FALSE}
#TOC {
    max-width: fit-content;
    white-space: nowrap;
}
  
div:has(> #TOC) {
    display: flex;
    flex-direction: row-reverse;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load required libraries
library(mvtnorm)
```

# Group sequential designs

## Simulations of GSD stopping probabilities

First, let us replicate the table of known stopping probabilities for the following group sequential design:

* Number of analyses: 3
* Upper bound stopping: $\mathbf{u} = (2.5, 2, 1.5)$
* Lower bound stopping: $\boldsymbol{\ell} = (0, 0.75, 1.5)$
* Number of patients at each analysis: 20
* Null hypothesis: $\theta = 0$
* Alternative hypothesis: $\theta = \delta = 0.5$
* Known variance: $\sigma^2 = 1$

Probabilities are as follows:

|          | $\theta = 0$           |                        | $\theta = 0.5$         |                        |
|----------|------------------------|------------------------|------------------------|------------------------|
| Analysis | Prob stop for futility | Prob stop for efficacy | Prob stop for futility | Prob stop for efficacy |
| 1        | 0.500                  | 0.006                  | 0.057                  | 0.179                  |
| 2        | 0.299                  | 0.019                  | 0.042                  | 0.420                  |
| 3        | 0.137                  | 0.038                  | 0.049                  | 0.253                  |

First, let us simulate the straightforward case of Analysis 1 **under the null**.

For futility:
```{r}
theta <- 0
sigma2 <- 1

z_vec <- c()

for (i in 1:50000) {
  x1 <- rnorm(20)
  x2 <- rnorm(20)

  mean.diff <- mean(x1 - x2)

  z <- mean.diff * sqrt( 20 / (2*sigma2) )
  
  z_vec[i] <-  z
}

mean(z_vec <= 0)
```

For efficacy:
```{r}
for (i in 1:50000) {
  x1 <- rnorm(20)
  x2 <- rnorm(20)

  mean.diff <- mean(x1 - x2)

  z <- mean.diff * sqrt( 20 / (2*sigma2) )
  
  z_vec[i] <-  z
}

mean(z_vec >= 2.5)
```

Now, Analysis 1 **under the alternative**.

For futility:
```{r}
theta <- 0.5
sigma2 <- 1

z_vec <- c()

for (i in 1:50000) {
  x1 <- rnorm(20, mean = theta, sd = sqrt(sigma2))
  x2 <- rnorm(20)

  mean.diff <- mean(x1 - x2)

  z <- mean.diff * sqrt( 20 / (2*sigma2) )
  
  z_vec[i] <-  z
}

mean(z_vec <= 0)
```


For efficacy:
```{r}
theta <- 0.5
sigma2 <- 1

z_vec <- c()

for (i in 1:50000) {
  x1 <- rnorm(20, mean = theta, sd = sqrt(sigma2))
  x2 <- rnorm(20)

  mean.diff <- mean(x1 - x2)

  z <- mean.diff * sqrt( 20 / (2*sigma2) )
  
  z_vec[i] <-  z
}

mean(z_vec >= 2.5)
```

Now, the case of all three analyses **under the null**.

```{r}
theta <- 0
sigma2 <- 1

z_vec <- c()
z2_vec <- c()
z3_vec <- c()

analysis2_count <- 0
analysis3_count <- 0

for (i in 1:100000) {
  x1 <- rnorm(20)
  x2 <- rnorm(20)

  mean.diff <- mean(x1 - x2)

  z <- mean.diff * sqrt( 20 / (2*sigma2) )
  
  z_vec[i] <-  z
  
  if ( (z > 0) & (z < 2.5) ) {
    
    analysis2_count <- analysis2_count + 1
    
    x3 <- rnorm(20)
    x4 <- rnorm(20)
    
    x1 <- c(x1, x3)
    x2 <- c(x2, x4)
    
    mean.diff <- mean(x1 - x2)
    
    z2 <- mean.diff * sqrt( 40 / (2*sigma2) )
    
    z2_vec[analysis2_count] <- z2
    
    if ( (z2 > 0.75) & (z2 < 2) ) {
      
      analysis3_count <- analysis3_count + 1
      
      x5 <- rnorm(20)
      x6 <- rnorm(20)
    
      x1 <- c(x1, x3, x5)
      x2 <- c(x2, x4, x6)
    
      mean.diff <- mean(x1 - x2)
    
      z3 <- mean.diff * sqrt( 60 / (2*sigma2) )
    
      z3_vec[analysis3_count] <- z3
      
    }
    
  }
  
}
```


For futility:

```{r}
mean(z_vec <= 0)

mean(z_vec > 0 & z_vec < 2.5) * mean(z2_vec <= 0.75) 

mean(z_vec > 0 & z_vec < 2.5) * mean(z2_vec > 0.75 & z2_vec < 2) * mean(z3_vec < 1.5)
```

For efficacy:

```{r}
mean(z_vec > 2.5)

mean(z_vec > 0 & z_vec < 2.5) * mean(z2_vec > 2) 

mean(z_vec > 0 & z_vec < 2.5) * mean(z2_vec > 0.75 & z2_vec < 2) * mean(z3_vec > 1.5)
```

Now, the case of all three analyses **under the alternative**.

```{r}
theta <- 0.5
sigma2 <- 1

z_vec <- c()
z2_vec <- c()
z3_vec <- c()

analysis2_count <- 0
analysis3_count <- 0

for (i in 1:100000) {
  x1 <- rnorm(20, mean = theta)
  x2 <- rnorm(20)

  mean.diff <- mean(x1 - x2)

  z <- mean.diff * sqrt( 20 / (2*sigma2) )
  
  z_vec[i] <-  z
  
  if ( (z > 0) & (z < 2.5) ) {
    
    analysis2_count <- analysis2_count + 1
    
    x3 <- rnorm(20, mean = theta)
    x4 <- rnorm(20)
    
    x1 <- c(x1, x3)
    x2 <- c(x2, x4)
    
    mean.diff <- mean(x1 - x2)
    
    z2 <- mean.diff * sqrt( 40 / (2*sigma2) )
    
    z2_vec[analysis2_count] <- z2
    
    if ( (z2 > 0.75) & (z2 < 2) ) {
      
      analysis3_count <- analysis3_count + 1
      
      x5 <- rnorm(20, mean = theta)
      x6 <- rnorm(20)
    
      x1 <- c(x1, x3, x5)
      x2 <- c(x2, x4, x6)
    
      mean.diff <- mean(x1 - x2)
    
      z3 <- mean.diff * sqrt( 60 / (2*sigma2) )
    
      z3_vec[analysis3_count] <- z3
      
    }
    
  }
  
}
```


For futility:

```{r}
mean(z_vec <= 0)

mean(z_vec > 0 & z_vec < 2.5) * mean(z2_vec <= 0.75) 

mean(z_vec > 0 & z_vec < 2.5) * mean(z2_vec > 0.75 & z2_vec < 2) * mean(z3_vec <= 1.5)
```

For efficacy:

```{r}
mean(z_vec > 2.5)

mean(z_vec > 0 & z_vec < 2.5) * mean(z2_vec >= 2) 

mean(z_vec > 0 & z_vec < 2.5) * mean(z2_vec > 0.75 & z2_vec < 2) * mean(z3_vec >= 1.5)
```

## Function for GSDs

In order to generate a function, we need the following information:

* Number of analyses
* Upper bound stopping vector $\mathbf{u}$
* Lower bound stopping vector $\mathbf{l}$
* Number of patients at each analysis as a vector $\mathbf{n}$
* Null hypothesis value for $\theta$
* Alternative hypothesis value for $\delta$
* Known variance: $\sigma^2$

The length of the upper and lower bound vectors should be equal to the number of analyses that are planned. The length of the number of patients at each analysis vector should also be equal to the number of analyses that are planned.

```{r}
gsd_simulations <- function(n_analyses = 3, 
                            upper_bounds = c(2.5, 2, 1.5),
                            lower_bounds = c(0, 0.75, 1.5),
                            n_patients = c(20, 40, 60),
                            null_hypothesis = 0,
                            alt_hypothesis = 0.5,
                            variance = 1) {
  
  # sanity checks
  if(length(upper_bounds) != n_analyses) print("Warning: number of upper bounds must equal number of analyses")
  if(length(lower_bounds) != n_analyses) print("Warning: number of lower bounds must equal number of analyses")
  if(length(n_patients) != n_analyses) print("Warning: number of patients vector must equal number of analyses")
  
  if(length(upper_bounds) != length(lower_bounds)) {
    print("Warning: number of upper bounds must equal number of analyses")
  }
  
  # assign values for null and alt hypotheses
  theta_0 <- null_hypothesis
  delta <- alt_hypothesis
  
  # empty mean vectors to fill
  mean_0 <- c()
  mean_1 <- c()
  
  # need to parse the upper and lower boundaries of the design
  # for futility and efficacy, must put the bounds of integration correctly 
  # for pmvnorm
  futility_l_bounds <- list()
  futility_u_bounds <- list()
  efficacy_l_bounds <- list()
  efficacy_u_bounds <- list()

  n_analyses <- length(upper_bounds)

  for (i in 1:n_analyses) {
    
    # special case of i = 1
    if (i == 1) {
      futility_l_bounds[[i]] <- lower_bounds[i]
      futility_u_bounds[[i]] <- upper_bounds[i]
      efficacy_l_bounds[[i]] <- lower_bounds[i]
      efficacy_u_bounds[[i]] <- upper_bounds[i]
      next
    }
    
    # all other cases
    futility_l_bounds[[i]] <- c(lower_bounds[1:i-1], -Inf)
    futility_u_bounds[[i]] <- c(upper_bounds[1:i-1], lower_bounds[i])
    
    efficacy_l_bounds[[i]] <- c(lower_bounds[1:i-1], upper_bounds[i])
    efficacy_u_bounds[[i]] <- c(upper_bounds[1:i-1], Inf)
  }
  
  # list of probabilities to return
  probs_to_return <- list()
  
  # list of SIGMAs
  SIGMA_list <- list()
    
  for (i in 1:n_analyses) {
    if (i == 1) next
    
    # start with diagonal matrix for SIGMA
    SIGMA <- diag(nrow = i)
    
    # n = 2, need to fill all but 11, 22
    # n = 3, need to fill all but 11, 22, 33
    # n = 4, need to fill all but 11, 22, 33, 44
    # etc. 
    for(i in 1:i) {
      for(j  in 1:i) {
        
        # leave the 1s on the diagonal, skip this iteration of for loop
        if(i == j) next
        
        # when i is less than j, the lower number of patients will be in numerator
        if(i < j) SIGMA[i,j] <- sqrt(n_patients[i] / n_patients[j])
        
        # when i is greater than j, the lower number of patients will be in numerator
        if(i > j) SIGMA[i,j] <- sqrt(n_patients[j] / n_patients[i])
        
      }
    }
    
    SIGMA_list[[i]] <- SIGMA
  }
  
  
  for (i in 1:n_analyses) {
    
    ##############
    # ANALYSIS 1 #
    ##############
    if(i == 1) {
      # mean under null
      mean_0[i] <- theta_0 * sqrt(n_patients[i]/(2*variance))
      
      # mean under alternative
      mean_1[i] <- delta * sqrt(n_patients[i]/(2*variance))
      
      # prob stop for futility, null
      futility_null <- pnorm(futility_l_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance))
      
      # prob stop for efficacy, null
      efficacy_null <- pnorm(efficacy_u_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance), 
                             lower.tail = FALSE)
  
      # prob stop for futility, alt
      futility_alt <- pnorm(futility_l_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance))
      
      # prob stop for efficacy
      efficacy_alt <- pnorm(efficacy_u_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance), 
                            lower.tail = FALSE)
      
      probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
      names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
      
      next
    }
    
    ######################
    # ALL OTHER ANALYSES #
    ######################
    
    # next mean under null
    mean_0[i] <- theta_0 * sqrt(n_patients[i] / (2 * variance))
    
    # next mean under alternative
    mean_1[i] <- delta * sqrt(n_patients[i]/ (2*variance))
    
    # bounds for these will be same
    # futility under null
    futility_null <- pmvnorm(lower = futility_l_bounds[[i]], 
                             upper = futility_u_bounds[[i]], 
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    futility_alt <- pmvnorm(lower = futility_l_bounds[[i]], 
                            upper = futility_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    # bounds for these will be same
    # futility under null
    efficacy_null <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                             upper = efficacy_u_bounds[[i]],
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    efficacy_alt <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                            upper = efficacy_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
    names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
    
  }
  
  
  # return the probabilities
  probs_to_return
}
```


```{r}
gsd_simulations(n_analyses = 4,
                upper_bounds = c(2.5, 2, 1.8, 1.5),
                lower_bounds = c(0, 0.75, 1, 1.5),
                n_patients = c(20, 40, 60, 80),
                null_hypothesis = 0,
                alt_hypothesis = 0.5,
                variance = 1)
```

## Calculate expected sample size

The expected sample size is calculated across a set of possible true treatment effects $\boldsymbol{\delta} = \{\delta_1, \delta_2, \dots, \delta_n \}$ as a function of the design elements (1) number of analyses $k = \{1, 2, \dots, K\}$, (2) number of patients at each analysis $\mathbf{n} = \{n_1, n_2, \dots, n_K\}$, (3) the upper and lower bounds $\mathbf{u} = (u_1, u_2, \dots, u_K)$ and $\boldsymbol{\ell} = (\ell_1, \ell_2, \dots, \ell_K)$.

The expected sample size is:

$$
E[N \, | \, \delta]=\sum_{i=1}^K n_i P(\text{trial stops after analysis }i \, | \, \delta)
$$

The probability that the trial stops after analysis $i$ is the sum of the probabilities that the trial stops for efficacy after analysis $i$ and the probability that the trial stops for futility after analysis $i$.

$$
\begin{multline*}
E[N \, | \, \delta]=\sum_{i=1}^K n_i \Big[ P(\text{trial stops for efficacy after analysis }i \, | \, \delta) + \\ P(\text{trial stops for futility after analysis }i \, | \, \delta) \Big]
\end{multline*}
$$

Starting with the design given in `gsd_simulations()` function default, we can calculate the expected sample size under $\delta=0$ to start.

```{r}
probs_to_return <- gsd_simulations(alt_hypothesis = 0)
```

This loop then pulls the probabilities under the alternative (given above as $\delta=0$ in the function call).

```{r}
# example function inputs
n_patients = c(20, 40, 60)
n_analyses = 3

# vector to collect the probabilities
sum_probs <- c()

for (i in 1:n_analyses) {
  
  # pull the probabilities from the list
  tmp_probs <- probs_to_return[[i]]
  
  # gather them into a vector
  sum_probs <- c(sum_probs, sum(tmp_probs[3:4]))
  
}

# calculate the effective sample size
ess <- sum(n_patients * sum_probs)
```

We can add this loop to the function `gsd_simulations()` and then we can graph the effective sample size over a vector of alternative hypotheses $\boldsymbol{\delta}$.

```{r}
gsd_simulations <- function(n_analyses = 3, 
                            upper_bounds = c(2.5, 2, 1.5),
                            lower_bounds = c(0, 0.75, 1.5),
                            n_patients = c(20, 40, 60),
                            null_hypothesis = 0,
                            alt_hypothesis = 0.5,
                            variance = 1) {
  
  # sanity checks
  if(length(upper_bounds) != n_analyses) print("Warning: number of upper bounds must equal number of analyses")
  if(length(lower_bounds) != n_analyses) print("Warning: number of lower bounds must equal number of analyses")
  if(length(n_patients) != n_analyses) print("Warning: number of patients vector must equal number of analyses")
  
  if(length(upper_bounds) != length(lower_bounds)) {
    print("Warning: number of upper bounds must equal number of analyses")
  }
  
  # assign values for null and alt hypotheses
  theta_0 <- null_hypothesis
  delta <- alt_hypothesis
  
  # empty mean vectors to fill
  mean_0 <- c()
  mean_1 <- c()
  
  # need to parse the upper and lower boundaries of the design
  # for futility and efficacy, must put the bounds of integration correctly 
  # for pmvnorm
  futility_l_bounds <- list()
  futility_u_bounds <- list()
  efficacy_l_bounds <- list()
  efficacy_u_bounds <- list()

  n_analyses <- length(upper_bounds)

  for (i in 1:n_analyses) {
    
    # special case of i = 1
    if (i == 1) {
      futility_l_bounds[[i]] <- lower_bounds[i]
      futility_u_bounds[[i]] <- upper_bounds[i]
      efficacy_l_bounds[[i]] <- lower_bounds[i]
      efficacy_u_bounds[[i]] <- upper_bounds[i]
      next
    }
    
    # all other cases
    futility_l_bounds[[i]] <- c(lower_bounds[1:i-1], -Inf)
    futility_u_bounds[[i]] <- c(upper_bounds[1:i-1], lower_bounds[i])
    
    efficacy_l_bounds[[i]] <- c(lower_bounds[1:i-1], upper_bounds[i])
    efficacy_u_bounds[[i]] <- c(upper_bounds[1:i-1], Inf)
  }
  
  # list of probabilities to return
  probs_to_return <- list()
  
  # list of SIGMAs
  SIGMA_list <- list()
    
  for (i in 1:n_analyses) {
    if (i == 1) next
    
    # start with diagonal matrix for SIGMA
    SIGMA <- diag(nrow = i)
    
    # n = 2, need to fill all but 11, 22
    # n = 3, need to fill all but 11, 22, 33
    # n = 4, need to fill all but 11, 22, 33, 44
    # etc. 
    for(i in 1:i) {
      for(j  in 1:i) {
        
        # leave the 1s on the diagonal, skip this iteration of for loop
        if(i == j) next
        
        # when i is less than j, the lower number of patients will be in numerator
        if(i < j) SIGMA[i,j] <- sqrt(n_patients[i] / n_patients[j])
        
        # when i is greater than j, the lower number of patients will be in numerator
        if(i > j) SIGMA[i,j] <- sqrt(n_patients[j] / n_patients[i])
        
      }
    }
    
    SIGMA_list[[i]] <- SIGMA
  }
  
  
  for (i in 1:n_analyses) {
    
    ##############
    # ANALYSIS 1 #
    ##############
    if(i == 1) {
      # mean under null
      mean_0[i] <- theta_0 * sqrt(n_patients[i]/(2*variance))
      
      # mean under alternative
      mean_1[i] <- delta * sqrt(n_patients[i]/(2*variance))
      
      # prob stop for futility, null
      futility_null <- pnorm(futility_l_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance))
      
      # prob stop for efficacy, null
      efficacy_null <- pnorm(efficacy_u_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance), 
                             lower.tail = FALSE)
  
      # prob stop for futility, alt
      futility_alt <- pnorm(futility_l_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance))
      
      # prob stop for efficacy
      efficacy_alt <- pnorm(efficacy_u_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance), 
                            lower.tail = FALSE)
      
      probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
      names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
      
      next
    }
    
    ######################
    # ALL OTHER ANALYSES #
    ######################
    
    # next mean under null
    mean_0[i] <- theta_0 * sqrt(n_patients[i] / (2 * variance))
    
    # next mean under alternative
    mean_1[i] <- delta * sqrt(n_patients[i]/ (2*variance))
    
    # bounds for these will be same
    # futility under null
    futility_null <- pmvnorm(lower = futility_l_bounds[[i]], 
                             upper = futility_u_bounds[[i]], 
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    futility_alt <- pmvnorm(lower = futility_l_bounds[[i]], 
                            upper = futility_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    # bounds for these will be same
    # futility under null
    efficacy_null <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                             upper = efficacy_u_bounds[[i]],
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    efficacy_alt <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                            upper = efficacy_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
    names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
    
  }
    
  # vector to collect the sum of futility and efficacy probabilities
  sum_probs <- c()
  
  for (i in 1:n_analyses) {
    
    # pull the probabilities from the list
    tmp_probs <- probs_to_return[[i]]
    
    # gather them into a vector
    # 3:4 because we want to calculate under the alternative
    sum_probs <- c(sum_probs, sum(tmp_probs[3:4]))
    
  }
  
  # calculate the effective sample size
  ess <- sum(n_patients * sum_probs)
  
  # add the effective sample size to the list
  return_values <- append(probs_to_return, ess)
  
  # name the list
  names_for_list <- as.vector(sapply("analysis_", paste0, 1:n_analyses))
  names_for_list <- c(names_for_list, "effective_sample_size")
  names(return_values) <- names_for_list
  
  # return probabilities and ESS
  return_values
}
```

Now we can test the function:

```{r}
gsd_simulations(alt_hypothesis = 0)
```

Finally, we can calculate the ESS over a range of values:

```{r}
ess_vector <- c()
delta_vector <- seq(from = 0, to = 1, length.out = 100)

for (i in 1:100) {
  ess_vector[i] <- gsd_simulations(alt_hypothesis = delta_vector[i])$effective_sample_size
}
```

Then, we can graph this:

```{r}
library(ggplot2)

ggplot() + 
  geom_line(mapping = aes(x = delta_vector, y = ess_vector)) +
  labs(x = "True \u03B4", y = "Effective sample size", 
       title = "Effective sample size over range of true \u03B4 values")
```


# Gaussian process regression



















